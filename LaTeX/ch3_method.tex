\chapter{Method}

\section{Datasets}
\label{sec:Datasets}


\subsection{Wisconsin}

The dataset used in this thesis, Breast Cancer Wisconsin (Diagnostic) dataset, was donated 1995 to UCI  Machine Learning Repository \parencite{dua:2017} by one of its creators, Nick Street. It contains 569 instances with 32 attributes describing the features of breast cancer. Each instance is classified as benign (357) or malignant (212). The 32 attributes describe ten real-value features which are:

\subsection{Royal Hallamshire Hospital}

Fine needle aspirates of breast lumps (FNAB) was collected from 692 patients at Royal Hallamshire Hospital, Sheffield, during 1992 - 1993. The FNABs 10 features of the FNABs was marked as present or non present. These features along with the patients's age defines the attributes of the dataset. In addition, the final outcome of benign disease or malignancy was confirmed by open biopsy where this result was available.

\subsection{MIAS database}

Mias database contain results from 119 data points with 5 features: Character of background tissue, Class of abnormality, X coordinate of centre of abnormality, Y coordinate of centre of abnormality, Approximate radius (in pixels). The features was extracted from 1024x1024 pixel images.

\subsection{Erlangen-Nuremberg}

Dataset collected from a Breast Imaging-Reporting and Data System (BI-RADS) at the Institute of Radiology of the University Erlangen-Nuremberg between 2003 and 2006. It contains three features assessed as a discrete value from a double-review by physicians along with the patients' age.

\input{snippets/table_datasets}


\section{Implementation}

The implementation outline is a straightforward approach. Each dataset will be split into training and test data. For each classifier each FS-method will select all possible subsets in turn. The classifier will be trained on the subset and evaluated on the test data. A compact pseudocode is presented in algorithm \ref{alg:pseudo_code}. The steps is more more thoroughly detailed below. 

\input{snippets/implementation_pseudo}

\subsection{Classifiers}
All classifiers was implemented with Scikit \parencite{scikit-learn}. The parameters of every classifier was left to default. The parametrs default values are found in table \ref{table:classifier_params}.

\input{snippets/table_parameters}


\subsection{Feature selection}

The feature selection consisted of two parts. First, the filter methods which was implemented with the \textit{Select K best} method, provided by Scikit \parencite{scikit-learn}. Second, the wrapper methods which was implemented with the \textit{SequentialFeatureSelector} method, provided in mlextend library \parencite{mlextend}.


\section{Evaluation}

\textbf{ Pawel: Add formulas on how we evaluate and how results are produces. Also, section on ANOVA. }



During experiments each dataset is loaded and split into training and test data with a ratio of 3:1. The same training and test data is used for every classifier. Each classifier is tested iteratively with each filter method. The accuracy is the computed mean of 10 fold cross validation on the test set.

\subsection{Explaining differences between datasets}

It is needful to evaluate the difference between datasets. The differences among the datasets allows to study how effects of FS-methods generalises between different data and if results are consistent. To explain any inconsistencies analysis of variance (ANOVA) test will be performed. ANOVA entails if differences in results between groups can be explained by variance or if there is a statistically significant difference between groups.

The groups of interest are FS-methods and datasets. To quantify these groups we need a value for each dataset and FS-method. This value is computed in two steps. First, averaging accuracy of all classifiers given a fold of data with a given FS-method. Secondly, choose the best accuracy of a fold produced by subset of the data. Using these values with ANOVA a F-score can be computed. F-score measures the probability of rejecting the null hypothesis, that difference combinations of datasets and FS-methods are alike.

% Pawel: Describe all configurations of classifiers and feature selection methods, discuss how you choose parameters, train them (on what data with what algorithms etc.)
